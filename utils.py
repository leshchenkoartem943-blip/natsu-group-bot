import config
import os
import sys
import json
import uuid
import hashlib
import random
import requests
import re
import threading
import time
import asyncio
from datetime import datetime
import webbrowser
from tkinter import simpledialog, messagebox
import tkinter as tk

def log_msg(tag, text):
    if config.log_queue:
        config.log_queue.put((tag, text))
    print(f"[{tag}] {text}") # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
# === –°–ò–°–¢–ï–ú–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
def get_hwid():
    try:
        mac = uuid.getnode()
        return hashlib.md5(str(mac).encode()).hexdigest()
    except:
        return "unknown_hwid"

def resource_path(relative_path):
    try:
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)

# === –ü–†–û–ö–°–ò –ò –£–°–¢–†–û–ô–°–¢–í–ê ===
def get_random_proxy():
    if not config.MY_PROXIES: return None
    proxy_str = random.choice(config.MY_PROXIES)
    try:
        parts = proxy_str.strip().split(":")
        if len(parts) == 4:
            return {
                'proxy_type': 'http',
                'addr': parts[0],
                'port': int(parts[1]),
                'username': parts[2],
                'password': parts[3],
                'rdns': True 
            }
    except: pass
    return None

def check_single_proxy(proxy_str):
    try:
        parts = proxy_str.strip().split(":")
        if len(parts) != 4: return False
        ip, port, user, pwd = parts
        proxy_url = f"http://{user}:{pwd}@{ip}:{port}"
        r = requests.get("http://www.google.com", proxies={"http": proxy_url, "https": proxy_url}, timeout=5)
        return r.status_code == 200
    except: return False

def ensure_device_config(session_data):
    return get_random_device_config()

def get_random_device_config():
    models = [
        {"device_model": "Samsung Galaxy S24 Ultra", "system_version": "Android 14"},
        {"device_model": "Xiaomi 14 Pro", "system_version": "Android 14"},
        # ... –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
    ]
    base = {"app_version": "10.9.1", "lang_code": "en", "system_lang_code": "en-US"}
    base.update(random.choice(models))
    return base

# === FIREBASE & LOGS ===
def firebase_patch(path, data):
    try: requests.patch(f"{config.FIREBASE_DB_URL}{path}.json", json=data, timeout=10)
    except: pass

def firebase_get(path):
    try:
        resp = requests.get(f"{config.FIREBASE_DB_URL}{path}.json", timeout=10)
        return resp.json() if resp.status_code == 200 else None
    except: return None

def update_daily_stats_firebase():
    try:
        my_hwid = get_hwid()
        today = datetime.now().strftime("%Y-%m-%d")
        path = f"/config/users/{my_hwid}/stats"
        current = firebase_get(path)
        new_count = (current.get("count", 0) + 1) if current and current.get("date") == today else 1
        firebase_patch(path, {"date": today, "count": new_count})
    except: pass

def push_log_firebase(text):
    try:
        path = f"/config/users/{get_hwid()}"
        ts = datetime.now().strftime("[%H:%M] ")
        firebase_patch(path, {"last_log": ts + text})
    except: pass

def send_admin_log(action_name, details=""):
    try:
        import platform
        hwid = get_hwid()
        msg = f"üîî <b>ACTIVATION ALERT</b>\nüÜî HWID: <code>{hwid}</code>\nüöÄ Action: {action_name}\nüìù Details: {details}"
        requests.post(f"https://api.telegram.org/bot{config.BOT_TOKEN}/sendMessage", 
                      data={"chat_id": config.ADMIN_ID, "text": msg, "parse_mode": "HTML"}, timeout=3)
        threading.Thread(target=lambda: push_log_firebase(f"{action_name}: {details[:50]}"), daemon=True).start()
    except: pass

def auto_register_in_firebase():
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ.
    """
    try:
        hwid = get_hwid()
        name = get_registered_user()
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —é–∑–µ—Ä –≤ –±–∞–∑–µ
        path = f"/config/users/{hwid}"
        current_data = firebase_get(path)
        
        if current_data:
            # –Æ–ó–ï–† –£–ñ–ï –ï–°–¢–¨ -> –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—É –≤—Ö–æ–¥–∞ –∏ –∏–º—è
            payload = {
                "rename_to": name,
                "last_seen": now,
                "version": config.CURRENT_VERSION
            }
            # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ—Ç —Å—Ç–∞—Ç—É—Å–∞, —Å—Ç–∞–≤–∏–º active
            if "status" not in current_data:
                payload["status"] = "active"
                
            firebase_patch(path, payload)
            print(f"Firebase: –Æ–∑–µ—Ä {name} –æ–±–Ω–æ–≤–ª–µ–Ω.")
            
        else:
            # –Æ–ó–ï–† –ù–û–í–´–ô -> –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å
            payload = {
                "rename_to": name,
                "status": "active",
                "spy_mode": False,
                "message": "",
                "last_seen": now,
                "registered_at": now,
                "version": config.CURRENT_VERSION,
                "open_urls": [],
                "last_log": "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è..."
            }
            firebase_patch(path, payload)
            print(f"Firebase: –ù–æ–≤—ã–π —é–∑–µ—Ä {name} –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω!")
            
    except Exception as e:
        print(f"Auto-Register Error: {e}")

# === –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ===
# ==========================================


def get_registered_user():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å.
    –ï—Å–ª–∏ –Ω–µ—Ç - –ø—Ä–æ—Å–∏—Ç –≤–≤–µ—Å—Ç–∏ –∏–º—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –µ–≥–æ –Ω–∞–≤—Å–µ–≥–¥–∞.
    """
    # 1. –ï—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å - —á–∏—Ç–∞–µ–º –∏–º—è
    if os.path.exists(config.USER_FILE):
        try:
            with open(config.USER_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("name", "Unknown")
        except: pass

    # 2. –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç - —Ç—Ä–µ–±—É–µ–º –≤–≤–æ–¥
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–∫—Ä—ã—Ç–æ–µ –æ–∫–Ω–æ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
    temp_root = tk.Tk()
    temp_root.withdraw()
    
    user_name = ""
    while not user_name:
        user_name = simpledialog.askstring(
            "–ê–∫—Ç–∏–≤–∞—Ü–∏—è", 
            "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ –ò–ú–Ø –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ª–∏—Ü–µ–Ω–∑–∏–∏:\n(–ù–∞–ø—Ä–∏–º–µ—Ä: –ò–≤–∞–Ω)", 
            parent=temp_root
        )
        
        # –ï—Å–ª–∏ –Ω–∞–∂–∞–ª –û—Ç–º–µ–Ω–∞ –∏–ª–∏ –∫—Ä–µ—Å—Ç–∏–∫ - –∑–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É –∂–µ—Å—Ç–∫–æ
        if user_name is None:
            sys.exit()
            
        user_name = user_name.strip()
        if not user_name:
            messagebox.showwarning("–û—à–∏–±–∫–∞", "–ò–º—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º!")

    temp_root.destroy()

    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º—è –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–¥–º–∏–Ω—É —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–º —é–∑–µ—Ä–µ
    try:
        with open(config.USER_FILE, "w", encoding="utf-8") as f:
            json.dump({"name": user_name}, f, ensure_ascii=False)
            
        # –°—Ä–∞–∑—É —Å—Ç—É—á–∏–º —Ç–µ–±–µ, —á—Ç–æ –ø–æ—è–≤–∏–ª—Å—è –Ω–æ–≤–µ–Ω—å–∫–∏–π
        send_admin_log("üÜï –ù–û–í–ê–Ø –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø", f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª—Å—è –∫–∞–∫: {user_name}")
    except: pass
    
    return user_name

# === –†–ê–ë–û–¢–ê –° –§–ê–ô–õ–ê–ú–ò –ò –î–ê–ù–ù–´–ú–ò ===
def load_config(filepath="config.json"):
    defaults = {"delay_creation": "180", "delay_contact": "20", "random_delay": "1", "contact_mode": "0"}
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f: defaults.update(json.load(f))
        except: pass
    return defaults

def save_config(cfg, filepath="config.json"):
    try:
        with open(filepath, "w", encoding="utf-8") as f: json.dump(cfg, f, indent=4, ensure_ascii=False)
    except: pass

def load_sessions(filepath="sessions.json"):
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f: return json.load(f)
        except: pass
    return []

def save_sessions(sessions, filepath="sessions.json"):
    try:
        with open(filepath, "w", encoding="utf-8") as f: json.dump(sessions, f, indent=4)
    except: pass

def update_session_info(phone, full_name, username):
    sessions = load_sessions()
    for s in sessions:
        if s.get('phone') == phone:
            s['name'] = full_name
            s['username'] = username
            s['last_used'] = time.time()
            break
    save_sessions(sessions)

def parse_target_file(file_content):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä. 
    –ü–æ–Ω–∏–º–∞–µ—Ç:
    1. –ì–æ—Ç–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã (—Ñ–∏–æ: ..., –Ω–æ–º–µ—Ä: ...)
    2. –°—ã—Ä—ã–µ –±–∞–∑—ã (–û–û–û "–†–æ–≥–∞", —Å–ø–∏—Å–æ–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –∏ –§–ò–û)
    """
    data = {"company_name": "Unknown_Company", "candidates": []}

    # === –õ–û–ì–ò–ö–ê 1: –ß–¢–ï–ù–ò–ï –ì–û–¢–û–í–û–ì–û –û–¢–ß–ï–¢–ê ===
    # –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ—Ç—á–µ—Ç–∞
    if "—Ñ–∏–æ:" in file_content.lower() and "–Ω–æ–º–µ—Ä:" in file_content.lower():
        
        # 1. –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ —à–∞–ø–∫–µ –æ—Ç—á–µ—Ç–∞ "–û–¢–ß–ï–¢: –ù–∞–∑–≤–∞–Ω–∏–µ"
        report_header = re.search(r'–û–¢–ß–ï–¢:\s*(.+)', file_content)
        if report_header:
            data["company_name"] = report_header.group(1).strip()
        else:
            # –ò–ª–∏ –∏—â–µ–º –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –±–∞–∑–µ), –µ—Å–ª–∏ —à–∞–ø–∫–∏ –æ—Ç—á–µ—Ç–∞ –Ω–µ—Ç
            fallback_match = re.search(r'(?i)(?:–û–û–û|–ê–û|–ò–ü)?\s*["¬´‚Äú]([^"¬ª‚Äù]+)["¬ª‚Äù]', file_content)
            if fallback_match: 
                data["company_name"] = fallback_match.group(1).strip()

        # 2. –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º (-------)
        sections = re.split(r'-{5,}', file_content)

        for sec in sections:
            if not sec.strip(): continue
            
            # –ò—â–µ–º –Ω–æ–º–µ—Ä (—Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "–Ω–æ–º–µ—Ä:" –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –µ–≥–æ)
            phone_match = re.search(r'–Ω–æ–º–µ—Ä:\s*([+\d]+)', sec, re.IGNORECASE)
            
            if phone_match:
                phone = phone_match.group(1).strip()
                
                # –ò—â–µ–º –§–ò–û
                name_match = re.search(r'—Ñ–∏–æ:\s*(.+)', sec, re.IGNORECASE)
                full_name = name_match.group(1).strip() if name_match else "Unknown"
                
                # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è –∏–∑ –§–ò–û, –µ—Å–ª–∏ –æ–Ω–∞ —Ç–∞–º –µ—Å—Ç—å (–î–î.–ú–ú.–ì–ì–ì–ì)
                dob = ""
                dob_found = re.search(r'(\d{2}\.\d{2}\.\d{4})', full_name)
                if dob_found:
                    dob = dob_found.group(1)
                    # –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª–æ—Å—å —á–∏—Å—Ç–æ–µ –§–ò–û
                    full_name = full_name.replace(dob, "").strip()

                data["candidates"].append({
                    "full_name": full_name,
                    "dob": dob,
                    "phones": [phone]
                })
        
        return data

    # === –õ–û–ì–ò–ö–ê 2: –°–¢–ê–†–ê–Ø (–°–´–†–ê–Ø –ë–ê–ó–ê) ===
    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –æ—Ç—á–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    
    # 1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —à–∞–ø–∫—É –∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    parts = re.split(r'\+?={10,}', file_content)

    if len(parts) > 1:
        header_content = parts[0]
        candidates_content = "\n".join(parts[1:])
    else:
        header_content = file_content
        candidates_content = file_content # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è –Ω–µ—Ç, –∏—â–µ–º –≤–µ–∑–¥–µ

    # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏
    header_match = re.search(r'(?i)(?:–û–û–û|–ê–û|–ù–ü–ü|–ü–ê–û|–ó–ê–û|–ò–ü)\s*["¬´‚Äú]([^"¬ª‚Äù]+)["¬ª‚Äù]', header_content)
    if header_match: 
        data["company_name"] = header_match.group(1).strip()
    else:
        fallback_match = re.search(r'["¬´‚Äú]([^"¬ª‚Äù]+)["¬ª‚Äù]', header_content)
        if fallback_match:
            data["company_name"] = fallback_match.group(1).strip()

    # –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)
    candidate_sections = re.split(r'-{5,}', candidates_content)
    
    for sec in candidate_sections:
        if not sec.strip(): continue
        
        phones = []
        for line in sec.split('\n'):
            cl = re.sub(r'\D', '', line)
            # –§–∏–ª—å—Ç—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
            if (len(cl)==10 or len(cl)==11) and not cl.startswith('19') and not cl.startswith('20'):
                phones.append(cl)
        
        if phones:
            name = "Unknown"
            dob = "" 
            # –ò—â–µ–º –§–ò–û + –î–∞—Ç—É (—Å—Ç—Ä–æ–≥–æ–µ –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏)
            nm = re.search(r'^([–ê-–Ø–Å\s-]+)\s+(\d{2}\.\d{2}\.\d{4})', sec.strip(), re.MULTILINE)
            if nm: 
                name = nm.group(1).strip()
                dob = nm.group(2).strip()
            else:
                # –ò—â–µ–º –ø—Ä–æ—Å—Ç–æ –§–ò–û (2 —Å–ª–æ–≤–∞ –ö–ê–ü–°–û–ú)
                nm2 = re.search(r'^([–ê-–Ø–Å]{2,}\s+[–ê-–Ø–Å]{2,}(?:\s+[–ê-–Ø–Å]{2,})?)', sec.strip(), re.MULTILINE)
                if nm2: name = nm2.group(1).strip()
            
            data["candidates"].append({"full_name": name, "dob": dob, "phones": phones})

    return data

# ==========================================
# === –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê –í–´–ë–û–†–ê –°–ï–ö–¶–ò–ô ===
# ==========================================

def split_text_by_sections(full_text):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞—Ä—å: {'Global_Header': ..., '–°–µ–∫—Ü–∏—è1': content, ...}
    –ò—â–µ—Ç —Å—Ç—Ä–æ–∫–∏, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏–∑ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–ª–æ–≤ (–Ω–∞–ø—Ä. '–°–µ–∫—Ü–∏—è1 –°–µ–∫—Ü–∏—è1 –°–µ–∫—Ü–∏—è1')
    """
    # 1. –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Å–µ–∫—Ü–∏–π. 
    # –†–µ–≥—É–ª—è—Ä–∫–∞ –∏—â–µ—Ç –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏, —Å–ª–æ–≤–æ, –∑–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞ –º–∏–Ω–∏–º—É–º 2 —Ä–∞–∑–∞
    pattern = re.compile(r'(?m)^(\S+)(?:[ \t]+\1){2,}[ \t]*$')
    
    matches = list(pattern.finditer(full_text))
    
    if not matches:
        return None # –°–µ–∫—Ü–∏–π –Ω–µ—Ç, –æ–±—ã—á–Ω—ã–π —Ñ–∞–π–ª

    sections = {}
    
    # –í—Å–µ, —á—Ç–æ –¥–æ –ø–µ—Ä–≤–æ–π —Å–µ–∫—Ü–∏–∏ ‚Äî —ç—Ç–æ –ì–ª–æ–±–∞–ª—å–Ω–∞—è –®–∞–ø–∫–∞ (—Ç–∞–º –Ω–∞–∑–≤–∞–Ω–∏–µ –û–û–û)
    first_match_start = matches[0].start()
    global_header = full_text[:first_match_start]
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–º —Å–µ–∫—Ü–∏—è–º
    for i in range(len(matches)):
        # –ò–º—è —Å–µ–∫—Ü–∏–∏ –±–µ—Ä–µ–º –∏–∑ –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–≥–æ—Å—è —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–µ–∫—Ü–∏—è1")
        section_name = matches[i].group(1) 
        
        start_content = matches[i].end() # –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å–µ–∫—Ü–∏–∏
        
        # –ö–æ–Ω—Ç–µ–Ω—Ç –∏–¥–µ—Ç –¥–æ –Ω–∞—á–∞–ª–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å–µ–∫—Ü–∏–∏ –∏–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞
        if i + 1 < len(matches):
            end_content = matches[i+1].start()
        else:
            end_content = len(full_text)
            
        content_block = full_text[start_content:end_content]
        
        # –í–ê–ñ–ù–û: –°–∫–ª–µ–∏–≤–∞–µ–º –®–∞–ø–∫—É + –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å + –ö–æ–Ω—Ç–µ–Ω—Ç —Å–µ–∫—Ü–∏–∏
        # –≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –ø–∞—Ä—Å–µ—Ä –ø–æ—Ç–æ–º –Ω–∞—à–µ–ª –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ —à–∞–ø–∫–µ
        separator = "\n" + "="*40 + "\n" 
        sections[section_name] = global_header + separator + content_block

    return sections

def extract_profile_data(text):
    """
    –ü–∞—Ä—Å–∏—Ç:
    1. –ò–º—è –∫–æ–º–ø–∞–Ω–∏–∏ (–æ—á–∏—â–µ–Ω–Ω–æ–µ, —Å —É—á–µ—Ç–æ–º –∏–≥–Ω–æ—Ä-–ª–∏—Å—Ç–∞ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä)
    2. –§–ò–û –î–∏—Ä–µ–∫—Ç–æ—Ä–∞ (–ë–µ—Ä–µ—Ç —Å—Ç—Ä–æ–∫—É –°–¢–†–û–ì–û –ù–ê–î "–ò–ù–ù")
    """
    company_name = "Company"
    dir_first = "Director"
    dir_last = ""
    
    # --- 1. –ü–ê–†–°–ò–ù–ì –ö–û–ú–ü–ê–ù–ò–ò ---
    ignore_list = [
        "–ì–ê–û–£ –î–ü–û", "–ì–ê–û–£ –í–û", "–ì–û–£ –í–ü–û", "–ì–û–£ –í–û", "–ù–û–£ –í–ü–û", 
        "–§–ì–ê–û–£ –í–û", "–§–ì–ê–û–£ –í–ü–û", "–§–ì–ë–í–û–£ –í–û", "–ö–ì–ë–ù–£–ö", "–ú–ë–£–ö–î–û", 
        "–§–ì–ë–ù–ò–£", "–§–ì–ö–í–û–£", "–§–ì–ë–ù–£", "–§–ì–ë–û–£", "–§–ì–ë–£–ö", "–§–ì–ë–£–ù", 
        "–§–ì–ö–û–£", "–ì–ê–ü–û–£", "–ì–ë–ü–û–£", "–ì–ö–ë–£–ö", "–ì–û–ë–£–ö", "–ö–ì–ê–£–ö", 
        "–ö–ì–ë–£", "–ö–ì–ö–£", "–ú–ê–û–£", "–ú–ê–£–ö", "–ú–ë–û–£", "–ú–ë–£–î–û", "–ú–ë–£–ö", 
        "–ú–ö–£–ö", "–û–ì–ê–£–ö", "–û–ì–ë–£–ö", "–û–ì–ö–£–ö", "–§–ì–û–£", "–§–ì–£–ü", "–§–ö–£–ö", 
        "–ß–ü–û–£", "–û–ê–ù–û", "–û–ë–£–ö", "–ì–ü–û–£", "–ê–£–ö", "–ë–£–ö", "–ì–£–ö", 
        "–ì–ê–£–ö", "–ì–ë–û–£", "–ì–ë–£–ö", "–ì–ö–ë–£", "–ì–ö–£–ö", "–ú–£–ö", "–ö–ì–£", 
        "–ú–ê–£", "–ú–ë–£", "–ú–ö–£", "–§–ì–£", "–§–ö–£", "–§–ì–ë–£", "–ì–ê–û–£", "–ì–ë–£", 
        "–ì–ö–£", "–ì–û–£", "–ù–ü–ü", "–û–û–û", "–ü–ê–û", "–ó–ê–û", "–ê–û", "–ò–ü", 
        "–ê–£", "–ë–£", "–ì–£", "–ú–£"
    ]
    sorted_prefixes = sorted(ignore_list, key=len, reverse=True)
    pattern_str = "|".join(sorted_prefixes)
    
    # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
    comp_match = re.search(fr'(?i)(?:{pattern_str})\s*["¬´‚Äú]([^"¬ª‚Äù]+)["¬ª‚Äù]', text)
    if comp_match:
        company_name = comp_match.group(1).strip()
    else:
        fallback = re.search(r'["¬´‚Äú]([^"¬ª‚Äù]+)["¬ª‚Äù]', text)
        if fallback: company_name = fallback.group(1).strip()

    # --- 2. –ü–ê–†–°–ò–ù–ì –î–ò–†–ï–ö–¢–û–†–ê (–ü–û –Ø–ö–û–†–Æ "–ò–ù–ù") ---
    try:
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É, –≥–¥–µ –µ—Å—Ç—å "–ò–ù–ù" –∏ –∑–∞—Ç–µ–º —Ü–∏—Ñ—Ä—ã (–¥–∏—Ä–µ–∫—Ç–æ—Ä—Å–∫–∏–π –ò–ù–ù –æ–±—ã—á–Ω–æ —Ç–∞–∫ –ø–∏—à–µ—Ç—Å—è)
        # (?m) –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å ^ (–Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏) –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞
        inn_iter = re.finditer(r'(?m)^\s*–ò–ù–ù\s+\d+', text)
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ (–æ–±—ã—á–Ω–æ –æ–Ω–æ –≤ —à–∞–ø–∫–µ –ø–æ–¥ –§–ò–û)
        first_inn = next(inn_iter, None)
        
        if first_inn:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –î–û –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏ —Å –ò–ù–ù
            text_before = text[:first_inn.start()]
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –±–µ—Ä–µ–º –ü–û–°–õ–ï–î–ù–Æ–Æ –Ω–µ–ø—É—Å—Ç—É—é
            lines = [line.strip() for line in text_before.split('\n') if line.strip()]
            
            if lines:
                fio_line = lines[-1] # –≠—Ç–æ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å—Ç—Ä–æ–∫–∞ "–ö–æ–∑–ª–æ–≤–∞ –Ø–Ω–∞ –Æ—Ä—å–µ–≤–Ω–∞ 15.06.1968"
                
                # 1. –£–±–∏—Ä–∞–µ–º –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è (–∏ –≤—Å—ë —á—Ç–æ –ø–æ—Å–ª–µ –Ω–µ—ë)
                # –ò—â–µ—Ç: –ø—Ä–æ–±–µ–ª + —Ü–∏—Ñ—Ä—ã.—Ü–∏—Ñ—Ä—ã.—Ü–∏—Ñ—Ä—ã + –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
                fio_clean = re.sub(r'\s+\d{1,2}\.\d{1,2}\.\d{4}.*$', '', fio_line).strip()
                
                # –ó–∞—â–∏—Ç–∞: –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if "–¥–æ–ª–∂–Ω–æ—Å—Ç–∏" not in fio_clean.lower() and len(fio_clean) > 3:
                    parts = fio_clean.split()
                    
                    # –û–∂–∏–¥–∞–µ–º: –§–∞–º–∏–ª–∏—è –ò–º—è [–û—Ç—á–µ—Å—Ç–≤–æ]
                    if len(parts) >= 2:
                        dir_last = parts[0].title()  # –§–∞–º–∏–ª–∏—è (–ö–æ–∑–ª–æ–≤–∞)
                        dir_first = parts[1].title() # –ò–º—è (–Ø–Ω–∞)
                    elif len(parts) == 1:
                        dir_first = parts[0].title()
                        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞: {e}")

    return company_name, dir_first, dir_last

def save_checked_report(original_file_path, selected_data, group_name):
    try:
        # 1. –ß–∏—Ç–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª (—à–∞–ø–∫—É)
        header_text = ""
        try:
            with open(original_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                parts = re.split(r'={10,}', content)
                if parts:
                    header_text = parts[0].strip()
                else:
                    header_text = content.strip()
        except: pass

        # 2. –í—Ä–µ–º—è
        import datetime as dt_safe
        current_time = dt_safe.datetime.now().strftime('%Y-%m-%d %H:%M')

        # 3. –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        lines = []
        lines.append(header_text)
        lines.append("\n\n" + "="*30)
        lines.append("="*30)
        lines.append(f"–û–¢–ß–ï–¢: {group_name}")
        lines.append(f"–î–∞—Ç–∞: {current_time}")
        lines.append("="*30 + "\n")

        for item in selected_data:
            fio = item.get('target_fio', 'Unknown')
            phone = item.get('phone', 'Unknown')
            dob = item.get('dob', '') # –î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è
            
            user_obj = item.get('user')
            
            # –°–æ–±–∏—Ä–∞–µ–º –ò–º—è –≤ –¢–ì
            tg_first = user_obj.first_name if user_obj and user_obj.first_name else ""
            tg_last = user_obj.last_name if user_obj and user_obj.last_name else ""
            tg_name = f"{tg_first} {tg_last}".strip()
            if not tg_name: tg_name = "–ë–µ–∑ –∏–º–µ–Ω–∏"
            
            # –°–æ–±–∏—Ä–∞–µ–º –Æ–∑–µ—Ä–Ω–µ–π–º
            raw_username = user_obj.username if user_obj and user_obj.username else None
            username_str = f"@{raw_username}" if raw_username else "-"

            # === [–ò–ó–ú–ï–ù–ï–ù–ò–Ø –ó–î–ï–°–¨] ===
            
            # –°—Ç—Ä–æ–∫–∞ 1: –§–ò–û + –î–∞—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            dob_suffix = f" {dob}" if dob else ""
            lines.append(f"—Ñ–∏–æ: {fio}{dob_suffix}")
            
            # –°—Ç—Ä–æ–∫–∞ 2: –ù–æ–º–µ—Ä
            lines.append(f"–Ω–æ–º–µ—Ä: {phone}")
            
            # –°—Ç—Ä–æ–∫–∞ 3: –ò–º—è –¢–ì / –Æ–∑–µ—Ä–Ω–µ–π–º
            lines.append(f"–∫–∞–∫ –ø–æ–¥–ø–∏—Å–∞–Ω –≤ —Ç–≥: {tg_name} / {username_str}")
            
            lines.append("-" * 20)

        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º
        folder = "–ø—Ä–æ–ø–∏—Å–∞–Ω–Ω—ã–µ –±–∞–∑—ã"
        if not os.path.exists(folder): os.makedirs(folder)
        
        safe_name = re.sub(r'[\\/*?:"<>|]', "", group_name).strip()
        if not safe_name: safe_name = "Report"
        
        new_filename = f"{safe_name}.txt"
        save_path = os.path.join(folder, new_filename)

        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
            
        log_msg("SUCCESS", f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {new_filename}")

    # === [–ù–û–í–û–ï] –û–¢–ö–†–´–í–ê–ï–ú –§–ê–ô–õ –°–†–ê–ó–£ –ü–û–°–õ–ï –°–û–•–†–ê–ù–ï–ù–ò–Ø ===
        try:
            os.startfile(save_path)
            log_msg("INFO", "üìÇ –§–∞–π–ª –æ—Ç—á–µ—Ç–∞ –æ—Ç–∫—Ä—ã—Ç.")
        except Exception as e_open:
            log_msg("WARN", f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {e_open}")
        # =====================================================

    except Exception as e:
        log_msg("ERROR", f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")

def save_remaining_report(data_list, prefix="rest"):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ –≤ —Ñ–∞–π–ª.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π [{'phone':..., 'name':...}]
    """
    if not data_list: return

    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞: rest_ProjectA_2025-12-19_14-30.txt
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
        filename = f"{prefix}_{timestamp}.txt"
        
        # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–π
        folder = "–æ—Å—Ç–∞—Ç–∫–∏"
        if not os.path.exists(folder): os.makedirs(folder)
        
        filepath = os.path.join(folder, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"–û–°–¢–ê–¢–û–ö –ö–û–ù–¢–ê–ö–¢–û–í ({len(data_list)} —à—Ç)\n")
            f.write("="*30 + "\n")
            for item in data_list:
                ph = item.get('phone', 'Unknown')
                nm = item.get('name', 'Unknown')
                f.write(f"{ph} | {nm}\n")
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø–∞–ø–∫—É –∏–ª–∏ —Ñ–∞–π–ª (—á—Ç–æ–±—ã —é–∑–µ—Ä —É–≤–∏–¥–µ–ª)
        try: os.startfile(filepath)
        except: pass
        
        messagebox.showwarning("–í–ù–ò–ú–ê–ù–ò–ï", f"–ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–ª–∏–º–∏—Ç/–æ—à–∏–±–∫–∞)!\n–û—Å—Ç–∞–≤—à–∏–µ—Å—è {len(data_list)} –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:\n{filename}")
        log_msg("WARN", f"üíæ –û—Å—Ç–∞—Ç–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filename}")

    except Exception as e:
        log_msg("ERROR", f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–∞: {e}")


# üìù –õ–û–ì–ò–ö–ê –ó–ê–ú–ï–¢–û–ö
NOTES_FILE = "notes_data.json"

def load_notes():
    if os.path.exists(NOTES_FILE):
        try:
            with open(NOTES_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: pass
    return {}

def save_notes_to_file(data):
    try:
        with open(NOTES_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        messagebox.showerror("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", str(e))

def sanitize_title(name):
    t = (name or "").strip()
    t = re.sub(r"\s+", " ", t)
    if not t: t = f"Group {random.randint(1000, 9999)}"
    return t[:128]

def generate_group_names(base, count):
    cfg = load_config()
    use_words = int(cfg.get("use_random_words", "1"))
    names = []
    if not use_words:
        raw_names = [base for _ in range(count)]
    else:
        seps = [s.strip() for s in cfg.get("separators", "|").splitlines() if s.strip()] or ["|"]
        words = [w.strip() for w in cfg.get("words", "Chat").splitlines() if w.strip()] or ["Chat"]
        raw_names = []
        
        for _ in range(count):
             raw_names.append(f"{base} {random.choice(seps)} {random.choice(words)}")
    return raw_names

async def smart_sleep(base_delay, is_random):
    if is_random:
        delay = random.uniform(5.0, 15.0)
        log_msg("WAIT", f"‚è≥ –°–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...")
    else:
        delay = float(base_delay)
        log_msg("WAIT", f"‚è≥ –ü–∞—É–∑–∞ {delay:.1f} —Å–µ–∫...")
    await asyncio.sleep(delay)